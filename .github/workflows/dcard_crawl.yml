name: Dcard Crawl

on:
  workflow_dispatch: # 可手動觸發
  schedule:
    - cron: '0 10 * * *'  # 每天 18:00 台北時間 (UTC+8 → 10:00 UTC)

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: 3.11

    - name: Install dependencies
      run: |
        pip install --upgrade pip
        pip install selenium undetected-chromedriver pandas webdriver-manager

    - name: Create data folder
      run: |
        mkdir -p data

    - name: Run Dcard crawler
      run: |
        python scripts/Dcard_crawler.py data/

    - name: Commit and push CSV files
      run: |
        git config --global user.name "github-actions"
        git config --global user.email "github-actions@github.com"
        git add data/*.csv
        git commit -m "Update crawled CSVs [skip ci]" || echo "No changes to commit"
        git push origin main
